#************hbase准备

#8020        namenode RPC交互端口
#8021        JT RPC交互端口
#50030       mapred.job.tracker.http.address        JobTracker administrative web GUI
##JOBTRACKER的HTTP服务器和端口
#50070              dfs.http.address                             NameNode administrative web GUI
##NAMENODE的HTTP服务器和端口
#50010          dfs.datanode.address                   DataNode control port (each DataNode listens on this port and registers it with the  NameNode on startup)
##DATANODE控制端口，主要用于DATANODE初始化时向NAMENODE提出注册和应答请求
#50020          dfs.datanode.ipc.address               DataNode IPC port, used for block transfer
##DATANODE的RPC服务器地址和端口
#50060      mapred.task.tracker.http.address           Per TaskTracker web interface
##TASKTRACKER的HTTP服务器和端口
#50075          dfs.datanode.http.address                  Per   DataNode web interface
##DATANODE的HTTP服务器和端口
#50090            dfs.secondary.http.address             Per secondary NameNode web interface
##辅助DATANODE的HTTP服务器和端口

#HBase
#HMaster 60010 hbase.master.info.port
#HRegionServer 60030 hbase.regionserver.info.port

#hadoop集群
nn:
  image: nn_base:latest
  ports:
    - "50070:50070"
    - "8020:8020"
    - "8021:8021"
    - "1022:22"


dn1:
  image: dn_base:latest
  links:
    - nn:namenode1
  environment:
    HDFSNAMENODERPC_SERVICE_HOST: namenode1
    HDFSNAMENODERPC_SERVICE_PORT: 8020
  ports:
    - "50075:50075"

dn2:
  image: dn_base:latest
  links:
    - nn:namenode1
  environment:
    HDFSNAMENODERPC_SERVICE_HOST: namenode1
    HDFSNAMENODERPC_SERVICE_PORT: 8020
  ports:
    - "50076:50075"
#
#datanode3:
#  image: bioshrek/hadoop-hdfs-datanode:cdh5
#  links:
#    - namenode:namenode1
#  environment:
#    HDFSNAMENODERPC_SERVICE_HOST: namenode1
#    HDFSNAMENODERPC_SERVICE_PORT: 8020
#  ports:
#    - "50077:50075"
#
zk:
  image: jplock/zookeeper:latest
  ports:
    - "2181:2181"
    - "2888"
    - "3888"

hb:
  #image: bioshrek/hbase-master:cdh5
  image: hmaster_base:latest
  links:
    - nn:namenode1
    - zk:zookeeper1
  environment:
    #HBASEMASTERIPC_SERVICE_PORT: 60000
    HBASEMASTERIPC_SERVICE_PORT_SERVICE_PORT: 60000
    HDFSNAMENODERPC_SERVICE_HOST: namenode1
    HDFSNAMENODERPC_SERVICE_PORT: 8020
    ZOOKEEPERCLIENT_SERVICE_HOST: zookeeper1
    ZOOKEEPERCLIENT_SERVICE_PORT: 2181
  ports:
    - "60010:60010"

rs:
  #image: bioshrek/hbase-regionserver:cdh5
  image: hregionserver_base:latest
  links:
    - nn:namenode2
    - zk:zookeeper2
    - hb:hbase1
  environment:
    HBASEMASTERIPC_SERVICE_HOST: hbase1
    HBASEMASTERIPC_SERVICE_PORT: 60010
    HBASEMASTERIPC_SERVICE_PORT_SERVICE_PORT: 60000
    HDFSNAMENODERPC_SERVICE_HOST: namenode2
    HDFSNAMENODERPC_SERVICE_PORT: 8020
    ZOOKEEPERCLIENT_SERVICE_HOST: zookeeper2
    ZOOKEEPERCLIENT_SERVICE_PORT: 2181
  ports:
    - "60030:60030"

#web namenode http://192.168.59.103:50075/
#web hbase #web http://192.168.59.103:60010/
#web regionserver http://192.168.59.103:60030/

#*************kafka

##消息队列，配置ip and port
kafka1:
  image: wurstmeister/kafka:latest
  ports:
    - "9092:9092"
  links:
    - zk:zk
  environment:
    KAFKA_BROKER_ID: 1
    KAFKA_ADVERTISED_HOST_NAME: 192.168.59.103
    KAFKA_ADVERTISED_PORT: 9092
    #KAFKA_MESSAGE_MAX_BYTES: 2000000
    KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'

##消息队列，配置ip and port
#kafka2:
#  image: wurstmeister/kafka:latest
#  ports:
#    - "9093:9092"
#  links:
#    - zk:zk
#  environment:
#    KAFKA_BROKER_ID: 2
#    KAFKA_ADVERTISED_HOST_NAME: 192.168.59.103
#    KAFKA_ADVERTISED_PORT: 9093
#    #KAFKA_MESSAGE_MAX_BYTES: 2000000
#    KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
#
###消息队列，配置ip and port
#kafka3:
#  image: wurstmeister/kafka:latest
#  ports:
#    - "9094:9092"
#  links:
#    - zk:zk
#  environment:
#    KAFKA_BROKER_ID: 3
#    KAFKA_ADVERTISED_HOST_NAME: 192.168.59.103
#    KAFKA_ADVERTISED_PORT: 9094
#    #KAFKA_MESSAGE_MAX_BYTES: 2000000
#    KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'

#及时消息
#注意端口
#启动fig start/fig stop
#fig scale kafka1=2
#kafka-topics.sh --create --zookeeper 192.168.59.103:2181 --replication-factor 1 --partitions 1 --topic test
#kafka-topics.sh --describe --topic test --zookeeper 192.168.59.103:2181
#kafka-topics.sh --list --zookeeper 192.168.59.103:2181
#kafka-console-producer.sh --broker-list 192.168.59.103:9092,192.168.59.103:9093,192.168.59.103:9094 --topic test
#kafka-console-consumer.sh --zookeeper 192.168.59.103:2181 --topic test --from-beginning

#***************flume
flume:
  image: flume_base:latest
  environment:
    FLUME_AGENT_NAME: producer
    FLUME_CONF_FILE: /var/tmp/flume.conf.mykafka
  ports:
    - "44444:44444"
  links:
    - kafka1

#建立通道
#kafka-topics.sh --create --zookeeper 192.168.59.103:2181 --replication-factor 1 --partitions 1 --topic mykafka
#生产数据
#telnet 192.168.59.103 44444
#消费数据
#kafka-console-consumer.sh --zookeeper 192.168.59.103:2181 --topic mykafka --from-beginning
#ok,数据到消费端显示出来